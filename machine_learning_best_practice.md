# 1）问题定义
- 明确业务目标，任务类型
- 选择性能指标（结合任务类型、标签数据分布）

# 2）数据管理
- 隔离测试集，避免数据泄漏
- 可以使用sklearn的train_test_split()，对数据进行拆分
- 如果标签分布明显有偏，或根据业务背景某些字段对预测影响较大，则需要分层采样stratify

# 3）数据探索
1. 数据集基本情况：譬如数据有多大，每个字段各是什么类型，可以使用head()、info()、describe()、value_counts()
2. 重复值、缺失值和异常值：去除重复值，检查缺失值是否严重、缺失值是否有特殊含义，如何发现异常值
3. 特征之间是否冗余：比如身高的单位用cm和m表示就存在冗余，可以通过特征间相似性分析来找出冗余特征
4. 是否存在时间信息：当存在时间信息时，通常要进行相关性、趋势性、周期性和异常点的分析，同时还有可能涉及潜在的数据穿越问题
5. 标签分布：对于分类问题，是否存在类别分布不均衡。对于回归问题，是否存在异常值、整体分布如何，是否需要进行目标转换，譬如log转换
6. 训练集与测试集的分布：是否存在很多在测试集中存在的特征字段在训练集中没有。
7. 单变量/多变量分布，初步理解特征之间、特征与目标值的相关性，可以使用corr()、scatter_matrix()
    - 熟悉特征的分布情况，为每个数值属性绘制直方图，视情况进一步下钻可视化，可以使用df.hist()
    - 特征和标签的关系

# 4）数据准备
## 数据预处理
    1. 缺失值处理
        - 类别特征：作为一个新类别填充、或填充众数，可以使用simpleImputer
        - 数值特征：填充中位数(对异常值不敏感)、均值(对异常值较敏感)，可以使用simpleImputer
        - 有序数据：填充相邻值next或者previous
        - 模型预测填充：对含有缺失值的那一列进行建模并预测其中缺失值的结果，可以使用KNNImputer、interativeImputer
    2. 异常值处理
        - 寻找异常值：通过可视化分析发现异常值，譬如散点图、箱线图
        - 处理异常值：删除、视为缺失值、平均值(中位数)修正、不处理
    3. 无用特征处理
        - 对于属性分布极其不平衡的特征，可以考虑删除
        
## 特征变换
    1. 连续变量无量纲化（树类模型不需要）
        - 标准化：standardScaler()
        - 区间缩放：minmaxScaler()
    2. 连续变量数据变换
        - log变换：将倾斜数据变得接近正态分布，一般应用log(x+1)，对标签作log变换的实用函数有TransformedTargetRegressor()
        - 连续变量离散化
            - 无监督的离散化：等频分桶cut()、等距分桶qcut()
            - 有监督的离散化：参考GBDT+LR的经典实现，使用树模型返回叶子节点将连续值转化为离散值
    3. 类别特征转换
        - 自然数编码：适用于有意义的类别特征(即有顺序关系)，以及树类模型 LaberEncoder()/OrdinalEncoder()
        - 独热编码：OneHotEncoder()
        - 注意事项：
            - 把空值当作一个专属的分类值，fillNA("NONE")
            - 如分类属性有大量类别：1) 用与类别相关的有用数值特征来替换分类输入 2) 特征散列化 3) 分箱计数 4) embedding学习低纬向量
    4. 不规则特征变换
        - 不规则特征可能包含样本的很多信息，e.g.身份证字段

## 特征提取
    1. 类别相关的统计特征
        - 目标编码
            - 用目标变量(标签)的统计量对类别特征进行编码
            - 分类问题：统计正样本个数、负样本个数、正负样本的比例
            - 回归问题：统计目标均值、中位数、最值
            - 所有基于目标编码的特征都应该在训练集上计算，注意不能泄漏任何验证集的信息
            - 对于基数较高的类别特征，可能会有过拟合的风险，一般需要加入平滑性处理
        - count、nunique、ratio
            - count：统计类别特征的出现频次
            - nunique和ratio：经常会涉及多个类别特征的联合构造，譬如在广告场景下，用户ID看过几种广告ID、用户ID点击某类广告ID的频次占用户点击所有广告ID频次的比例
        - 类别特征之间的交叉组合
            - 为避免维度爆炸，不能盲目作交叉组合
            - 先根据业务逻辑判断，可以基于对数据集的直觉分析和业务理解来创建，譬如“年龄_性别”
            - 类别特征的基数过大，一般不适合作交叉
    2. 数值相关的统计特征
        - 数值特征之间的交叉组合：结合业务理解进行有意义的特征构造，譬如“基于房屋大小和售价，构造每平米的单价”
        - 类别特征和数值特征之间的交叉组合：通常是在类别特征的某个类别中计算数值特征的一些统计量，譬如均值、中位数和最值
        - 按行统计相关特征：直接对多列按行进行统计
    3. 时间特征
        - 分离出基本的时间特征，譬如年、季度、月、日、周末/工作日，尝试捕抓季节性规律
        - 构造时间差特征，譬如 用户首次行为日期与用户注册日期的时间差、用户当前行为与用户上次行为的时间差
    4. 多值特征
        - 某一列特征中每行都包含多个属性，基本的处理办法是完全展开，即把这列特征所包含的n个属性展开成n维稀疏矩阵，可以使用CountVectorizer()

## 特征选择
    1. 特征关联性分析
        - 皮尔逊相关系数/卡方检验/互信息法：解决共线性变量问题、衡量特征与标签的相关性 corr()
        - 过滤掉相似性大于一定阈值的特征，减少特征冗余；阈值一般很难量化，可以结合总特征量、整体相似分数两个角度来考虑
    2. 特征重要性分析
        - 基于树模型的feature_importance、线形模型的相关系数，进行评估
        - 不能作为绝对的参考依据；一般而言，只要特征不会导致过拟合，就可以选择重要性高的特征进行分析和扩展，对于重要性低的特征可以考虑移除
    3. 封装方法
        - 启发式方法
        - 递归消除特征法
    4. null importance特征选择方式

# 5）建模与筛选
    - 使用标准参数训练不同类别（例如，线性模型、朴素贝叶斯模型、SVM、随机森林、神经网络等）的许多快速模型，作为性能基准
    - 衡量和比较它们的性能，对于每个模型，使用N折交叉验证并计算N折数据上性能指标的均值和标准差
    - 分析每种算法最重要的变量
    - 执行一轮快速的特征选择和特征工程，对前面的5个步骤再执行一两次快速迭代
    - 列出前三到五个最有前途的模型，优先选择会犯不同类型错误的模型

# 6）模型调优
## 超参数优化
    除非要探索的超参数值非常少，否则优先选择随机搜索而不是网格搜索
    - 随机搜索：高维参数的首选（更高效覆盖最优区域）
    - 网格搜索：小参数空间适用（如3x3组合）
    - 贝叶斯优化：适用于训练时间长的模型（如深度学习）
## 模型集成
  - Stacking：用基模型预测结果作为新特征输入元模型
  - 投票机制：分类任务中综合多个模型的预测概率加权平均